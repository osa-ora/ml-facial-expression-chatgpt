{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da2a9544-7d58-4100-bc00-cf120ee00ac0",
   "metadata": {},
   "source": [
    "# Facical Expression Detection\n",
    "This model generated by ChatGPT to do expression analysis of faces for dataset from Kaggle (size 48x48 and grayscale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3656921f-0b8b-4481-80f2-f69286e6e9a8",
   "metadata": {},
   "source": [
    "Add the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6f3920-8425-451a-b3dc-a6e654d54ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c4e569-476b-4f1e-9ab3-bc02a62696d4",
   "metadata": {},
   "source": [
    "Download the dataset and validate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6646a96-f50c-46c2-b535-b43cd1f21859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Angry': 0, 'Disgust': 1, 'Fear': 2, 'Happy': 3, 'Sad': 4, 'Surprise': 5, 'Neutral': 6}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the dataset\n",
    "#url = \"https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/download/fer2013.csv\"\n",
    "filename = \"fer2013.csv\"\n",
    "#response = requests.get(url)\n",
    "#open(filename, \"wb\").write(response.content)\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "# Get the unique emotions in the \"emotion\" column\n",
    "emotions = data['emotion'].unique()\n",
    "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "# Map emotions to integers\n",
    "emotion_mapping = {emotion: i for i, emotion in enumerate(emotion_labels)}\n",
    "\n",
    "# Print the mapping\n",
    "print(emotion_mapping)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e21a7d-ef2b-4087-aef4-73dda61139c3",
   "metadata": {},
   "source": [
    "Data transformation and prepare the data as training and testing datasets (20% testing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e15b845-30f3-485c-a643-13c0e035003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the strings in the pixels column into a list of integers\n",
    "pixels = data['pixels'].str.split().apply(lambda x: np.array(x).astype(int))\n",
    "\n",
    "# Convert the list of integers to a numpy array\n",
    "images = np.vstack(pixels.values)\n",
    "\n",
    "# Reshape the array as needed\n",
    "images = np.reshape(images, (-1, 48, 48, 1))\n",
    "\n",
    "# Reshape the array as needed\n",
    "#images = np.reshape(images, (-1, 48, 48, 1))\n",
    "#images = np.array(data['pixels'].tolist(), dtype=np.uint8)\n",
    "#images = np.reshape(images, (-1, 48, 48, 1))\n",
    "labels = tf.keras.utils.to_categorical(data['emotion'], 7)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4db9ebf-f8ef-4a38-9a0a-8ff1f26d5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# Define the model using the Sequential API from TensorFlow's Keras library\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first Conv2D layer to the model\n",
    "# 32 filters of size (3, 3) with a ReLU activation function are applied to the input image\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "\n",
    "# Add a MaxPooling2D layer to the model\n",
    "# The layer will reduce the size of the feature maps by half after the Conv2D layer\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add the second Conv2D layer to the model\n",
    "# 64 filters of size (3, 3) with a ReLU activation function are applied to the output of the previous layer\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add another MaxPooling2D layer to the model\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add the third Conv2D layer to the model\n",
    "# 128 filters of size (3, 3) with a ReLU activation function are applied to the output of the previous layer\n",
    "model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "# Add a final MaxPooling2D layer to the model\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add a Flatten layer to the model\n",
    "# This layer will convert the 3D tensor output of the Conv2D layers into a 1D vector\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Add a dense layer to the model with 128 units and a ReLU activation function\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "# Add a dropout layer to the model with a rate of 0.5\n",
    "# This layer will randomly set 50% of the inputs to 0 during training to prevent overfitting\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# Add the final dense layer to the model with 7 units and a softmax activation function\n",
    "# This layer will provide the 7 class predictions for the emotion recognition task\n",
    "model.add(tf.keras.layers.Dense(7, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ef63f-ee75-47dd-ada4-3236c378b549",
   "metadata": {},
   "source": [
    "## Model Compilation\n",
    "The compile method is used to compile the model before training it. The optimizer argument specifies the optimization algorithm to be used during training, in this case 'adam' which is a popular stochastic gradient-based optimization algorithm. The loss argument defines the loss function to be used during training, which in this case is 'categorical_crossentropy'. This loss function is used for multi-class classification problems and measures the difference between predicted class probabilities and true labels. The metrics argument specifies the evaluation metric to be used to assess the model performance during training and testing, in this case 'accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9168f50d-fb90-4780-954d-0cc7ea6d9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a42e1b-65be-45c2-8f27-63083678ce6f",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "The following line trains the model on the training data X_train and the corresponding labels y_train\n",
    "The training process will run for a total of 10 epochs\n",
    "The batch size of 32 means the model will process 32 samples at a time before updating the model weights\n",
    "During the training process, the model will be evaluated on the validation data (X_test, y_test) and these results will be used to monitor the model's performance and prevent overfitting.\n",
    "The results of the training process will be stored in the history object, which can be used to visualize the model's training and validation accuracy/loss over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23103d5d-3fd6-4653-9810-375b32a82c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "898/898 [==============================] - 74s 82ms/step - loss: 1.8963 - accuracy: 0.2791 - val_loss: 1.6268 - val_accuracy: 0.3692\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 73s 81ms/step - loss: 1.5972 - accuracy: 0.3792 - val_loss: 1.4886 - val_accuracy: 0.4257\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 73s 81ms/step - loss: 1.5043 - accuracy: 0.4180 - val_loss: 1.4559 - val_accuracy: 0.4349\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 73s 82ms/step - loss: 1.4426 - accuracy: 0.4420 - val_loss: 1.3952 - val_accuracy: 0.4671\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 72s 80ms/step - loss: 1.3939 - accuracy: 0.4648 - val_loss: 1.3749 - val_accuracy: 0.4738\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 72s 81ms/step - loss: 1.3488 - accuracy: 0.4828 - val_loss: 1.3236 - val_accuracy: 0.4922\n",
      "Epoch 7/10\n",
      "898/898 [==============================] - 72s 81ms/step - loss: 1.3152 - accuracy: 0.4936 - val_loss: 1.3026 - val_accuracy: 0.5004\n",
      "Epoch 8/10\n",
      "898/898 [==============================] - 72s 80ms/step - loss: 1.2772 - accuracy: 0.5070 - val_loss: 1.3181 - val_accuracy: 0.5015\n",
      "Epoch 9/10\n",
      "898/898 [==============================] - 73s 82ms/step - loss: 1.2371 - accuracy: 0.5266 - val_loss: 1.2746 - val_accuracy: 0.5192\n",
      "Epoch 10/10\n",
      "898/898 [==============================] - 72s 81ms/step - loss: 1.2091 - accuracy: 0.5378 - val_loss: 1.2891 - val_accuracy: 0.5085\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c51e14-d8ea-4b87-ac44-0e7bb696247b",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "It will computes the loss and accuracy metrics for the test data. The input parameters for this method are X_test and y_test which represent the test data and target labels respectively. The verbose parameter is used to specify the level of verbosity. Setting verbose=0 means no output will be displayed during the evaluation process.\n",
    "The method returns two values, test_loss and test_acc, which represent the loss and accuracy metrics respectively. These values can be used to determine how well the model is performing on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ace0106-7ae1-45bc-b34f-2c2c343a7f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.5084981918334961\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dc0e78-28b8-458f-972d-2a17e7bec821",
   "metadata": {},
   "source": [
    "## Save the model\n",
    "It will uses the HDF5 (Hierarchical Data Format version 5). It is a file format for storing large amounts of data in a binary file format that can be efficiently read and written using Python and other programming languages. The extension .h5 indicates that the model is saved in HDF5 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cecc0f33-11ff-464b-93d1-de622e7aafc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('facial_expression_recognition_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
